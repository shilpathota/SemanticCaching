{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47a964a4",
   "metadata": {},
   "source": [
    "# L2: Build Your First Semantic Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cda54ef-4d5b-4e9f-8e80-6d525b45e498",
   "metadata": {},
   "source": [
    "In this lab, you’ll build a working semantic cache from scratch so you can see how each part works, and then you will implement it using Redis’s open source SDK and database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed5e084-66ab-4514-9d5d-abfccd532534",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a382c6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ea27bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6d1d5e-9eae-482b-951d-e61c4559ab67",
   "metadata": {},
   "source": [
    "## Load the FAQ Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c4d0cf-12a3-4da3-957a-db3e8a8f20cc",
   "metadata": {
    "height": 166
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.conda (Python 3.12.12)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n .conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from cache.faq_data_container import FAQDataContainer\n",
    "\n",
    "faq_data = FAQDataContainer()\n",
    "faq_df = faq_data.faq_df\n",
    "test_df = faq_data.test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667654ec-0f19-4141-b001-5c30efaf9df7",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.conda (Python 3.12.12)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n .conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "faq_df.head().style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8adb27b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\vinod\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\vinod\\anaconda3\\lib\\site-packages (0.34.4)\n",
      "Collecting huggingface_hub\n",
      "  Using cached huggingface_hub-1.1.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: transformers in c:\\users\\vinod\\anaconda3\\lib\\site-packages (4.55.2)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface_hub\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from transformers) (2.32.0)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from huggingface_hub) (2024.6.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (69.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vinod\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Using cached sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Using cached transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "Installing collected packages: huggingface_hub, tokenizers, transformers, sentence-transformers\n",
      "\n",
      "  Attempting uninstall: huggingface_hub\n",
      "\n",
      "    Found existing installation: huggingface-hub 0.34.4\n",
      "\n",
      "    Uninstalling huggingface-hub-0.34.4:\n",
      "\n",
      "      Successfully uninstalled huggingface-hub-0.34.4\n",
      "\n",
      "   ---------------------------------------- 0/4 [huggingface_hub]\n",
      "   ---------------------------------------- 0/4 [huggingface_hub]\n",
      "   ---------------------------------------- 0/4 [huggingface_hub]\n",
      "   ---------------------------------------- 0/4 [huggingface_hub]\n",
      "   ---------------------------------------- 0/4 [huggingface_hub]\n",
      "   ---------------------------------------- 0/4 [huggingface_hub]\n",
      "   ---------------------------------------- 0/4 [huggingface_hub]\n",
      "   ---------------------------------------- 0/4 [huggingface_hub]\n",
      "  Attempting uninstall: tokenizers\n",
      "   ---------------------------------------- 0/4 [huggingface_hub]\n",
      "    Found existing installation: tokenizers 0.21.4\n",
      "   ---------------------------------------- 0/4 [huggingface_hub]\n",
      "    Uninstalling tokenizers-0.21.4:\n",
      "   ---------------------------------------- 0/4 [huggingface_hub]\n",
      "      Successfully uninstalled tokenizers-0.21.4\n",
      "   ---------------------------------------- 0/4 [huggingface_hub]\n",
      "   ---------- ----------------------------- 1/4 [tokenizers]\n",
      "  Attempting uninstall: transformers\n",
      "   ---------- ----------------------------- 1/4 [tokenizers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "    Found existing installation: transformers 4.55.2\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "    Uninstalling transformers-4.55.2:\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "      Successfully uninstalled transformers-4.55.2\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "  Attempting uninstall: sentence-transformers\n",
      "   -------------------- ------------------- 2/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [sentence-transformers]\n",
      "    Found existing installation: sentence-transformers 2.2.2\n",
      "   ------------------------------ --------- 3/4 [sentence-transformers]\n",
      "    Uninstalling sentence-transformers-2.2.2:\n",
      "   ------------------------------ --------- 3/4 [sentence-transformers]\n",
      "      Successfully uninstalled sentence-transformers-2.2.2\n",
      "   ------------------------------ --------- 3/4 [sentence-transformers]\n",
      "   ------------------------------ --------- 3/4 [sentence-transformers]\n",
      "   ------------------------------ --------- 3/4 [sentence-transformers]\n",
      "   ------------------------------ --------- 3/4 [sentence-transformers]\n",
      "   ------------------------------ --------- 3/4 [sentence-transformers]\n",
      "   ------------------------------ --------- 3/4 [sentence-transformers]\n",
      "   ------------------------------ --------- 3/4 [sentence-transformers]\n",
      "   ------------------------------ --------- 3/4 [sentence-transformers]\n",
      "   ------------------------------ --------- 3/4 [sentence-transformers]\n",
      "   ---------------------------------------- 4/4 [sentence-transformers]\n",
      "\n",
      "Successfully installed huggingface_hub-0.36.0 sentence-transformers-5.1.2 tokenizers-0.22.1 transformers-4.57.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\vinod\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\vinod\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\vinod\\anaconda3\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 2.19.1 requires fsspec[http]<=2024.3.1,>=2023.1.0, but you have fsspec 2024.6.1 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers huggingface_hub transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embeddings-explanation",
   "metadata": {},
   "source": [
    "## Create Embeddings for Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06077b3",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "Could not import module 'PreTrainedModel'. Are this object's requirements defined correctly?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinod\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2292\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   2291\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._object_missing_backend:\n\u001b[32m-> \u001b[39m\u001b[32m2292\u001b[39m     missing_backends = \u001b[38;5;28mself\u001b[39m._object_missing_backend[name]\n\u001b[32m   2294\u001b[39m     \u001b[38;5;28;01mclass\u001b[39;00m \u001b[34;01mPlaceholder\u001b[39;00m(metaclass=DummyObject):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinod\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2322\u001b[39m, in \u001b[36m_get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   2319\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2320\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[32m   2321\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not import module \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Are this object\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms requirements defined correctly?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2322\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01me\u001b[39;00m\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._modules:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinod\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2320\u001b[39m, in \u001b[36m_get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   2319\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m2320\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[32m   2321\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not import module \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Are this object\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms requirements defined correctly?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2322\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01me\u001b[39;00m\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._modules:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinod\\anaconda3\\Lib\\importlib\\__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:995\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:488\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinod\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:74\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mintegrations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor_parallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     66\u001b[39m     _get_parameter_tp_plan,\n\u001b[32m     67\u001b[39m     distribute_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m     72\u001b[39m     verify_tp_plan,\n\u001b[32m     73\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mloss\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mloss_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LOSS_MAPPING\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mmasking_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ALL_MASK_ATTENTION_FUNCTIONS\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinod\\anaconda3\\Lib\\site-packages\\transformers\\loss\\loss_utils.py:21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BCEWithLogitsLoss, MSELoss\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mloss_d_fine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DFineForObjectDetectionLoss\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mloss_deformable_detr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinod\\anaconda3\\Lib\\site-packages\\transformers\\loss\\loss_d_fine.py:21\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_vision_available\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mloss_for_object_detection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     22\u001b[39m     box_iou,\n\u001b[32m     23\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mloss_rt_detr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RTDetrHungarianMatcher, RTDetrLoss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinod\\anaconda3\\Lib\\site-packages\\transformers\\loss\\loss_for_object_detection.py:32\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_vision_available():\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_transforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m center_to_corners_format\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mdice_loss\u001b[39m(inputs, targets, num_boxes):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinod\\anaconda3\\Lib\\site-packages\\transformers\\image_transforms.py:22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     23\u001b[39m     ChannelDimension,\n\u001b[32m     24\u001b[39m     ImageInput,\n\u001b[32m     25\u001b[39m     get_channel_dimension_axis,\n\u001b[32m     26\u001b[39m     get_image_size,\n\u001b[32m     27\u001b[39m     infer_channel_dimension_format,\n\u001b[32m     28\u001b[39m )\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExplicitEnum, TensorType, is_jax_tensor, is_tf_tensor, is_torch_tensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinod\\anaconda3\\Lib\\site-packages\\transformers\\image_utils.py:59\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torchvision_available():\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InterpolationMode\n\u001b[32m     61\u001b[39m     pil_torch_interpolation_mapping = {\n\u001b[32m     62\u001b[39m         PILImageResampling.NEAREST: InterpolationMode.NEAREST_EXACT,\n\u001b[32m     63\u001b[39m         PILImageResampling.BOX: InterpolationMode.BOX,\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m         PILImageResampling.LANCZOS: InterpolationMode.LANCZOS,\n\u001b[32m     68\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinod\\anaconda3\\Lib\\site-packages\\torchvision\\__init__.py:6\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinod\\anaconda3\\Lib\\site-packages\\torchvision\\_meta_registrations.py:163\u001b[39m\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m grad.new_empty((batch_size, channels, height, width))\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[38;5;129;43m@torch\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_custom_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimpl_abstract\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtorchvision::nms\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[34;43mmeta_nms\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mboxes should be a 2d tensor, got \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43mD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinod\\anaconda3\\Lib\\site-packages\\torch\\library.py:1069\u001b[39m, in \u001b[36mregister_fake.<locals>.register\u001b[39m\u001b[34m(func)\u001b[39m\n\u001b[32m   1068\u001b[39m     use_lib = lib\n\u001b[32m-> \u001b[39m\u001b[32m1069\u001b[39m \u001b[43muse_lib\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_register_fake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstacklevel\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_override\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_override\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinod\\anaconda3\\Lib\\site-packages\\torch\\library.py:219\u001b[39m, in \u001b[36mLibrary._register_fake\u001b[39m\u001b[34m(self, op_name, fn, _stacklevel, allow_override)\u001b[39m\n\u001b[32m    217\u001b[39m     func_to_register = fn\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m handle = \u001b[43mentry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfake_impl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc_to_register\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_override\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_override\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[38;5;28mself\u001b[39m._registration_handles.append(handle)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinod\\anaconda3\\Lib\\site-packages\\torch\\_library\\fake_impl.py:50\u001b[39m, in \u001b[36mFakeImplHolder.register\u001b[39m\u001b[34m(self, func, source, lib, allow_override)\u001b[39m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     46\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.qualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33malready has an fake impl registered at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     48\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.kernel.source\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     49\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_dispatch_has_kernel_for_dispatch_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mqualname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMeta\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     52\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.qualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     53\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33malready has an DispatchKey::Meta implementation via a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     56\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mregister_fake.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     57\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: operator torchvision::nms does not exist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[32m      3\u001b[39m encoder = SentenceTransformer(\u001b[33m\"\u001b[39m\u001b[33mall-mpnet-base-v2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m faq_embeddings = encoder.encode(faq_df[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m].tolist())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinod\\anaconda3\\Lib\\site-packages\\sentence_transformers\\__init__.py:15\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     export_dynamic_quantized_onnx_model,\n\u001b[32m     12\u001b[39m     export_optimized_onnx_model,\n\u001b[32m     13\u001b[39m     export_static_quantized_openvino_model,\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_encoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     CrossEncoder,\n\u001b[32m     17\u001b[39m     CrossEncoderModelCardData,\n\u001b[32m     18\u001b[39m     CrossEncoderTrainer,\n\u001b[32m     19\u001b[39m     CrossEncoderTrainingArguments,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mLoggingHandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinod\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_card\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainer\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinod\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautonotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m trange\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     AutoConfig,\n\u001b[32m     21\u001b[39m     AutoModelForSequenceClassification,\n\u001b[32m     22\u001b[39m     AutoTokenizer,\n\u001b[32m     23\u001b[39m     PretrainedConfig,\n\u001b[32m     24\u001b[39m     PreTrainedModel,\n\u001b[32m     25\u001b[39m     PreTrainedTokenizer,\n\u001b[32m     26\u001b[39m )\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PushToHubMixin\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinod\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2295\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: Could not import module 'PreTrainedModel'. Are this object's requirements defined correctly?"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "encoder = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "faq_embeddings = encoder.encode(faq_df[\"question\"].tolist())\n",
    "\n",
    "print(f\"Sample (first 10 dimensions): {faq_embeddings[0][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7f48c7",
   "metadata": {},
   "source": [
    "## Implement Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc2ee07",
   "metadata": {
    "height": 336
   },
   "outputs": [],
   "source": [
    "def cosine_dist(a: np.array, b: np.array):\n",
    "    \"\"\"Compute cosine distance between two sets of vectors.\"\"\"\n",
    "    a_norm = np.linalg.norm(a, axis=1)\n",
    "    b_norm = np.linalg.norm(b) if b.ndim == 1 else np.linalg.norm(b, axis=1)\n",
    "    sim = np.dot(a, b) / (a_norm * b_norm)\n",
    "    return 1 - sim\n",
    "\n",
    "\n",
    "def semantic_search(query: str) -> tuple:\n",
    "    \"\"\"Find the most similar FAQ question to the query.\"\"\"\n",
    "    query_embedding = encoder.encode([query])[0]\n",
    "\n",
    "    distances = cosine_dist(faq_embeddings, query_embedding)\n",
    "\n",
    "    # Find the most similar question (lowest distance)\n",
    "    best_idx = int(np.argmin(distances))\n",
    "    best_distance = distances[best_idx]\n",
    "\n",
    "    return best_idx, best_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b23383d-92e5-4dcc-9a6c-9c1ec0a1f35f",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "idx, distance = semantic_search(\n",
    "    \"How long will it take to get a refund for my order?\"\n",
    ")\n",
    "\n",
    "print(f\"Most similar FAQ: {faq_df.iloc[idx]['question']}\")\n",
    "print(f\"Answer: {faq_df.iloc[idx]['answer']}\")\n",
    "print(f\"Cosine distance: {distance:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e077a3",
   "metadata": {},
   "source": [
    "## Build a Simple Semantic Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccbf7d4",
   "metadata": {
    "height": 268
   },
   "outputs": [],
   "source": [
    "def check_cache(query: str, distance_threshold: float = 0.3):\n",
    "    \"\"\"\n",
    "    Semantic cache lookup for previously asked questions.\n",
    "    Returns a dictionary with answer if hit, None if miss.\n",
    "    \"\"\"\n",
    "    idx, distance = semantic_search(query)\n",
    "\n",
    "    if distance <= distance_threshold:\n",
    "        return {\n",
    "            \"prompt\": faq_df.iloc[idx][\"question\"],\n",
    "            \"response\": faq_df.iloc[idx][\"answer\"],\n",
    "            \"vector_distance\": float(distance),\n",
    "        }\n",
    "\n",
    "    return None  # Cache miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db33021a-ca15-4434-b79a-6e3067fe4a75",
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"Is it possible to get a refund?\",\n",
    "    \"I want my money back\",\n",
    "    \"What are your business hours?\",  # Should miss\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    result = check_cache(query, distance_threshold=0.3)\n",
    "    if result:\n",
    "        print(f\"✅ HIT: '{query}' -> {result['response'][:50]}...\")\n",
    "        print(f\"   Distance: {result['vector_distance']:.3f}\\n\")\n",
    "    else:\n",
    "        print(f\"❌ MISS: '{query}'\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eff1ff7",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Add entries to the cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d125c948",
   "metadata": {
    "height": 302
   },
   "outputs": [],
   "source": [
    "def add_to_cache(question: str, answer: str):\n",
    "    \"\"\"\n",
    "    Add a new Q&A pair to our simple in-memory cache.\n",
    "    Extends both the DataFrame and embeddings matrix.\n",
    "    \"\"\"\n",
    "    global faq_df, faq_embeddings\n",
    "\n",
    "    new_row = pd.DataFrame({\"question\": [question], \"answer\": [answer]})\n",
    "    faq_df = pd.concat([faq_df, new_row], ignore_index=True)\n",
    "\n",
    "    # Generate embedding for the new question\n",
    "    new_embedding = encoder.encode([question])\n",
    "\n",
    "    # Add to embeddings matrix\n",
    "    faq_embeddings = np.vstack([faq_embeddings, new_embedding])\n",
    "\n",
    "    print(f\"✅ Added to cache: '{question}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b65677-3bbe-4b59-800b-6c473a9fc4e4",
   "metadata": {
    "height": 370
   },
   "outputs": [],
   "source": [
    "print(\"Original cache size:\", len(faq_df))\n",
    "\n",
    "new_entries = [\n",
    "    (\n",
    "        \"What are your business hours?\",\n",
    "        \"We're open Monday-Friday 9 AM to 6 PM EST. Weekend support is available for urgent issues.\",\n",
    "    ),\n",
    "    (\n",
    "        \"Do you have a mobile app?\",\n",
    "        \"Yes! Our mobile app is available on both iOS and Android. Search for 'CustomerApp' in your app store.\",\n",
    "    ),\n",
    "    (\n",
    "        \"How do I update my payment method?\",\n",
    "        \"Go to Account Settings > Payment Methods to add, edit, or remove payment options.\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "for question, answer in new_entries:\n",
    "    add_to_cache(question, answer)\n",
    "\n",
    "print(f\"\\nCache now has {len(faq_df)} total entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4468662-9d6e-44ce-bf28-205f762e4cff",
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "test_extended_queries = [\n",
    "    \"What time do you open?\",  \n",
    "    \"Is there a phone app?\", \n",
    "    \"How can I change my payment method?\",\n",
    "]\n",
    "\n",
    "for query in test_extended_queries:\n",
    "    result = check_cache(query, distance_threshold=0.3)\n",
    "    if result:\n",
    "        print(f\"✅ HIT: '{query}' -> {result['response'][:50]}...\")\n",
    "        print(f\"   Distance: {result['vector_distance']:.3f}\\n\")\n",
    "    else:\n",
    "        print(f\"❌ MISS: '{query}'\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "why-vector-database",
   "metadata": {},
   "source": [
    "## Moving to Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26476bd-d96f-4a25-a75a-c05185f7f81a",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e03eeee-34e8-4878-943a-abca510f193d",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "\n",
    "try:\n",
    "    r = redis.Redis.from_url(REDIS_URL)\n",
    "    r.ping()\n",
    "    print(\"✅ Redis is running and accessible\")\n",
    "except redis.ConnectionError:\n",
    "    print(\"❌ Cannot connect to Redis\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e02f7c",
   "metadata": {},
   "source": [
    "### Using a Cache-Optimized Embedding Model (langcache-embed-v1)\n",
    "https://huggingface.co/redis/langcache-embed-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10959d24",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "from redisvl.utils.vectorize import HFTextVectorizer\n",
    "from redisvl.extensions.cache.embeddings import EmbeddingsCache\n",
    "\n",
    "langcache_embed = HFTextVectorizer(\n",
    "    model=\"redis/langcache-embed-v1\",\n",
    "    cache=EmbeddingsCache(redis_client=r, ttl=3600)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00485b3",
   "metadata": {},
   "source": [
    "### Create the Redis Semantic Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-redisvl-cache",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "from redisvl.extensions.cache.llm import SemanticCache\n",
    "\n",
    "cache = SemanticCache(\n",
    "    name=\"faq-cache\",\n",
    "    vectorizer=langcache_embed,\n",
    "    redis_client=r,\n",
    "    distance_threshold=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a37aeb1",
   "metadata": {},
   "source": [
    "### Load the Cache with FAQ Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fee799",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "for i in range(len(faq_df)):\n",
    "    cache.store(\n",
    "        prompt=faq_df.iloc[i][\"question\"],\n",
    "        response=faq_df.iloc[i][\"answer\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4baa002-c799-48e1-950e-3d3d6c2128c1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "result = cache.check(\"I need a refund for my purchase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02952a84-9fdf-47e4-85e2-c6af124c3d83",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cache-management",
   "metadata": {},
   "source": [
    "### Implement TTL (time-to-live) policy to keep cache fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ee59fc",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "cache.set_ttl(86400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a525b4",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## End-to-End LLM Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aec528-3312-4326-b791-3f26cffe0784",
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "from cache.config import load_openai_key\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "load_openai_key()\n",
    "\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=MODEL_NAME,\n",
    "    temperature=0.1,\n",
    "    max_tokens=150,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32b6a58-ed65-4e9f-8884-b6121ac724de",
   "metadata": {
    "height": 202
   },
   "outputs": [],
   "source": [
    "def get_llm_response(question: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful customer support assistant. Answer this customer question concisely and professionally:\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Provide a helpful response in 1-2 sentences. If you don't have specific information, give a general helpful response.\n",
    "    \"\"\"\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    return response.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e359c0b5-bf67-4c82-b24e-109f3ff4b990",
   "metadata": {
    "height": 336
   },
   "outputs": [],
   "source": [
    "from cache.evals import PerfEval\n",
    "\n",
    "perf_eval = PerfEval()\n",
    "\n",
    "test_questions = [\n",
    "    \"How can I get my money back?\",\n",
    "    \"I want a refund please\",\n",
    "    \"What's your return policy?\",\n",
    "    \"I forgot my password\",\n",
    "    \"Can you help me reset my password?\",\n",
    "    \"What are your shipping costs?\",\n",
    "    \"Do you offer installation services?\",\n",
    "    \"Can I schedule a phone call with support?\",\n",
    "    \"How do I cancel my subscription?\",\n",
    "    \"How much does shipping cost?\",\n",
    "    \"I need to cancel my account\",\n",
    "]\n",
    "\n",
    "perf_eval.set_total_queries(len(test_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddfcea2-8fa4-4cd8-b4eb-f6fae82a9c58",
   "metadata": {
    "height": 472
   },
   "outputs": [],
   "source": [
    "with perf_eval:\n",
    "    for i, question in enumerate(test_questions, 1):\n",
    "        print(f\"\\n[{i}] Question: '{question}'\")\n",
    "\n",
    "        perf_eval.start()\n",
    "\n",
    "        if cached_result := cache.check(question):\n",
    "            # Cache HIT\n",
    "            perf_eval.tick(\"cache_hit\")\n",
    "            print(\n",
    "                f\"    ✅ CACHE HIT (distance: {cached_result[0]['vector_distance']:.3f})\"\n",
    "            )\n",
    "            print(f\"    📋 Cached question: {cached_result[0]['prompt'][:80]}...\")\n",
    "            print(f\"    📋 Cached response: {cached_result[0]['response'][:80]}...\")\n",
    "        else:\n",
    "            # Cache MISS - call LLM\n",
    "            perf_eval.tick(\"cache_miss\")  # Time for cache check\n",
    "            print(f\"    ❌ CACHE MISS\")\n",
    "            print(f\"    🤖 Calling LLM... \", end=\"\")\n",
    "\n",
    "            # Call LLM and track the call\n",
    "            perf_eval.start()\n",
    "            llm_response = get_llm_response(question)\n",
    "            perf_eval.tick(\"llm_call\")\n",
    "            perf_eval.record_llm_call(MODEL_NAME, question, llm_response)\n",
    "            print(f\"    💬 LLM response: {llm_response[:80]}...\")\n",
    "            cache.store(prompt=question, response=llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bb2a96-9142-4a55-84da-92a575d0b2fc",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "np.mean(perf_eval.durations_by_label['cache_hit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b34bd-4b60-4a90-9201-307a73deecba",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "np.mean(perf_eval.durations_by_label['llm_call'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7069e3bf-a5ef-4a25-95ec-40b47006e727",
   "metadata": {},
   "source": [
    "<b>Note:</b> In the above experiment we measure the latency of the cache response and a mocked latency of an LLM call. The mocked LLM call is a dummy function that sleeps for a random amount of time. The randomness in the results mainly comes from the randomness we introduced to mock the LLM. The results show us what we can typically see in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad2948f-1b8f-4b32-8f6f-655df47d60e2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "cache.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
