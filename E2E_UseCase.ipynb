{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47a964a4",
   "metadata": {},
   "source": [
    "# E2E_UseCase: Build Your First Semantic Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cda54ef-4d5b-4e9f-8e80-6d525b45e498",
   "metadata": {},
   "source": [
    "In this lab, you‚Äôll build a working semantic cache from scratch so you can see how each part works, and then you will implement it using Redis‚Äôs open source SDK and database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed5e084-66ab-4514-9d5d-abfccd532534",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a382c6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e6d1d5e-9eae-482b-951d-e61c4559ab67",
   "metadata": {},
   "source": [
    "## Load the FAQ Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c4d0cf-12a3-4da3-957a-db3e8a8f20cc",
   "metadata": {
    "height": 166
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 FAQ entries\n",
      "Loaded 80 test queries\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from cache.faq_data_container import FAQDataContainer\n",
    "\n",
    "faq_data = FAQDataContainer()\n",
    "faq_df = faq_data.faq_df\n",
    "test_df = faq_data.test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "667654ec-0f19-4141-b001-5c30efaf9df7",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_5092b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5092b_level0_col0\" class=\"col_heading level0 col0\" >id</th>\n",
       "      <th id=\"T_5092b_level0_col1\" class=\"col_heading level0 col1\" >question</th>\n",
       "      <th id=\"T_5092b_level0_col2\" class=\"col_heading level0 col2\" >answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5092b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5092b_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_5092b_row0_col1\" class=\"data row0 col1\" >How do I get a refund?</td>\n",
       "      <td id=\"T_5092b_row0_col2\" class=\"data row0 col2\" >To request a refund, visit your orders page and select **Request Refund**. Refunds are processed within 3-5 business days.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5092b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5092b_row1_col0\" class=\"data row1 col0\" >1</td>\n",
       "      <td id=\"T_5092b_row1_col1\" class=\"data row1 col1\" >Can I reset my password?</td>\n",
       "      <td id=\"T_5092b_row1_col2\" class=\"data row1 col2\" >Click **Forgot Password** on the login page and follow the email instructions. Check your spam folder if you don't see the email.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5092b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5092b_row2_col0\" class=\"data row2 col0\" >2</td>\n",
       "      <td id=\"T_5092b_row2_col1\" class=\"data row2 col1\" >Where is my order?</td>\n",
       "      <td id=\"T_5092b_row2_col2\" class=\"data row2 col2\" >Use the tracking link sent to your email after shipping. Orders typically arrive within 2-7 business days depending on your location.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5092b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_5092b_row3_col0\" class=\"data row3 col0\" >3</td>\n",
       "      <td id=\"T_5092b_row3_col1\" class=\"data row3 col1\" >How long is the warranty?</td>\n",
       "      <td id=\"T_5092b_row3_col2\" class=\"data row3 col2\" >All electronic products include a 12-month warranty from the purchase date. Extended warranties are available for purchase.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5092b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_5092b_row4_col0\" class=\"data row4 col0\" >4</td>\n",
       "      <td id=\"T_5092b_row4_col1\" class=\"data row4 col1\" >Do you ship internationally?</td>\n",
       "      <td id=\"T_5092b_row4_col2\" class=\"data row4 col2\" >Yes, we ship to over 50 countries worldwide. International shipping fees and delivery times vary by destination.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f545b27970>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faq_df.head().style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embeddings-explanation",
   "metadata": {},
   "source": [
    "## Create Embeddings for Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a06077b3",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample (first 10 dimensions): [ 0.02746386  0.04248311 -0.02679519  0.0378673  -0.03876128 -0.00109461\n",
      " -0.01158355  0.03070289 -0.00653774 -0.0195577 ]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "encoder = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "faq_embeddings = encoder.encode(faq_df[\"question\"].tolist())\n",
    "\n",
    "print(f\"Sample (first 10 dimensions): {faq_embeddings[0][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7f48c7",
   "metadata": {},
   "source": [
    "## Implement Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fc2ee07",
   "metadata": {
    "height": 336
   },
   "outputs": [],
   "source": [
    "def cosine_dist(a: np.array, b: np.array):\n",
    "    \"\"\"Compute cosine distance between two sets of vectors.\"\"\"\n",
    "    a_norm = np.linalg.norm(a, axis=1)\n",
    "    b_norm = np.linalg.norm(b) if b.ndim == 1 else np.linalg.norm(b, axis=1)\n",
    "    sim = np.dot(a, b) / (a_norm * b_norm)\n",
    "    return 1 - sim\n",
    "\n",
    "\n",
    "def semantic_search(query: str) -> tuple:\n",
    "    \"\"\"Find the most similar FAQ question to the query.\"\"\"\n",
    "    query_embedding = encoder.encode([query])[0]\n",
    "\n",
    "    distances = cosine_dist(faq_embeddings, query_embedding)\n",
    "\n",
    "    # Find the most similar question (lowest distance)\n",
    "    best_idx = int(np.argmin(distances))\n",
    "    best_distance = distances[best_idx]\n",
    "\n",
    "    return best_idx, best_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b23383d-92e5-4dcc-9a6c-9c1ec0a1f35f",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar FAQ: How do I get a refund?\n",
      "Answer: To request a refund, visit your orders page and select **Request Refund**. Refunds are processed within 3-5 business days.\n",
      "Cosine distance: 0.331\n"
     ]
    }
   ],
   "source": [
    "idx, distance = semantic_search(\n",
    "    \"How long will it take to get a refund for my order?\"\n",
    ")\n",
    "\n",
    "print(f\"Most similar FAQ: {faq_df.iloc[idx]['question']}\")\n",
    "print(f\"Answer: {faq_df.iloc[idx]['answer']}\")\n",
    "print(f\"Cosine distance: {distance:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e077a3",
   "metadata": {},
   "source": [
    "## Build a Simple Semantic Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bccbf7d4",
   "metadata": {
    "height": 268
   },
   "outputs": [],
   "source": [
    "def check_cache(query: str, distance_threshold: float = 0.3):\n",
    "    \"\"\"\n",
    "    Semantic cache lookup for previously asked questions.\n",
    "    Returns a dictionary with answer if hit, None if miss.\n",
    "    \"\"\"\n",
    "    idx, distance = semantic_search(query)\n",
    "\n",
    "    if distance <= distance_threshold:\n",
    "        return {\n",
    "            \"prompt\": faq_df.iloc[idx][\"question\"],\n",
    "            \"response\": faq_df.iloc[idx][\"answer\"],\n",
    "            \"vector_distance\": float(distance),\n",
    "        }\n",
    "\n",
    "    return None  # Cache miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db33021a-ca15-4434-b79a-6e3067fe4a75",
   "metadata": {
    "height": 234
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ HIT: 'Is it possible to get a refund?' -> To request a refund, visit your orders page and se...\n",
      "   Distance: 0.262\n",
      "\n",
      "‚ùå MISS: 'I want my money back'\n",
      "\n",
      "‚ùå MISS: 'What are your business hours?'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_queries = [\n",
    "    \"Is it possible to get a refund?\",\n",
    "    \"I want my money back\",\n",
    "    \"What are your business hours?\",  # Should miss\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    result = check_cache(query, distance_threshold=0.3)\n",
    "    if result:\n",
    "        print(f\"‚úÖ HIT: '{query}' -> {result['response'][:50]}...\")\n",
    "        print(f\"   Distance: {result['vector_distance']:.3f}\\n\")\n",
    "    else:\n",
    "        print(f\"‚ùå MISS: '{query}'\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eff1ff7",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Add entries to the cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d125c948",
   "metadata": {
    "height": 302
   },
   "outputs": [],
   "source": [
    "def add_to_cache(question: str, answer: str):\n",
    "    \"\"\"\n",
    "    Add a new Q&A pair to our simple in-memory cache.\n",
    "    Extends both the DataFrame and embeddings matrix.\n",
    "    \"\"\"\n",
    "    global faq_df, faq_embeddings\n",
    "\n",
    "    new_row = pd.DataFrame({\"question\": [question], \"answer\": [answer]})\n",
    "    faq_df = pd.concat([faq_df, new_row], ignore_index=True)\n",
    "\n",
    "    # Generate embedding for the new question\n",
    "    new_embedding = encoder.encode([question])\n",
    "\n",
    "    # Add to embeddings matrix\n",
    "    faq_embeddings = np.vstack([faq_embeddings, new_embedding])\n",
    "\n",
    "    print(f\"‚úÖ Added to cache: '{question}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98b65677-3bbe-4b59-800b-6c473a9fc4e4",
   "metadata": {
    "height": 370
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original cache size: 8\n",
      "‚úÖ Added to cache: 'What are your business hours?'\n",
      "‚úÖ Added to cache: 'Do you have a mobile app?'\n",
      "‚úÖ Added to cache: 'How do I update my payment method?'\n",
      "\n",
      "Cache now has 11 total entries\n"
     ]
    }
   ],
   "source": [
    "print(\"Original cache size:\", len(faq_df))\n",
    "\n",
    "new_entries = [\n",
    "    (\n",
    "        \"What are your business hours?\",\n",
    "        \"We're open Monday-Friday 9 AM to 6 PM EST. Weekend support is available for urgent issues.\",\n",
    "    ),\n",
    "    (\n",
    "        \"Do you have a mobile app?\",\n",
    "        \"Yes! Our mobile app is available on both iOS and Android. Search for 'CustomerApp' in your app store.\",\n",
    "    ),\n",
    "    (\n",
    "        \"How do I update my payment method?\",\n",
    "        \"Go to Account Settings > Payment Methods to add, edit, or remove payment options.\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "for question, answer in new_entries:\n",
    "    add_to_cache(question, answer)\n",
    "\n",
    "print(f\"\\nCache now has {len(faq_df)} total entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4468662-9d6e-44ce-bf28-205f762e4cff",
   "metadata": {
    "height": 234
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ HIT: 'What time do you open?' -> We're open Monday-Friday 9 AM to 6 PM EST. Weekend...\n",
      "   Distance: 0.289\n",
      "\n",
      "‚úÖ HIT: 'Is there a phone app?' -> Yes! Our mobile app is available on both iOS and A...\n",
      "   Distance: 0.265\n",
      "\n",
      "‚úÖ HIT: 'How can I change my payment method?' -> Go to Account Settings > Payment Methods to add, e...\n",
      "   Distance: 0.118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_extended_queries = [\n",
    "    \"What time do you open?\",  \n",
    "    \"Is there a phone app?\", \n",
    "    \"How can I change my payment method?\",\n",
    "]\n",
    "\n",
    "for query in test_extended_queries:\n",
    "    result = check_cache(query, distance_threshold=0.3)\n",
    "    if result:\n",
    "        print(f\"‚úÖ HIT: '{query}' -> {result['response'][:50]}...\")\n",
    "        print(f\"   Distance: {result['vector_distance']:.3f}\\n\")\n",
    "    else:\n",
    "        print(f\"‚ùå MISS: '{query}'\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "why-vector-database",
   "metadata": {},
   "source": [
    "## Moving to Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c26476bd-d96f-4a25-a75a-c05185f7f81a",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e03eeee-34e8-4878-943a-abca510f193d",
   "metadata": {
    "height": 166
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Redis is running and accessible\n"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "\n",
    "try:\n",
    "    r = redis.Redis.from_url(REDIS_URL)\n",
    "    r.ping()\n",
    "    print(\"‚úÖ Redis is running and accessible\")\n",
    "except redis.ConnectionError:\n",
    "    print(\"‚ùå Cannot connect to Redis\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e02f7c",
   "metadata": {},
   "source": [
    "### Using a Cache-Optimized Embedding Model (langcache-embed-v1)\n",
    "https://huggingface.co/redis/langcache-embed-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10959d24",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:37:46 sentence_transformers.SentenceTransformer INFO   Use pytorch device_name: cpu\n",
      "17:37:46 sentence_transformers.SentenceTransformer INFO   Load pretrained SentenceTransformer: redis/langcache-embed-v1\n"
     ]
    }
   ],
   "source": [
    "from redisvl.utils.vectorize import HFTextVectorizer\n",
    "from redisvl.extensions.cache.embeddings import EmbeddingsCache\n",
    "\n",
    "langcache_embed = HFTextVectorizer(\n",
    "    model=\"redis/langcache-embed-v1\",\n",
    "    cache=EmbeddingsCache(redis_client=r, ttl=3600)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00485b3",
   "metadata": {},
   "source": [
    "### Create the Redis Semantic Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "setup-redisvl-cache",
   "metadata": {
    "height": 149
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:38:16 redisvl.index.index INFO   Index already exists, not overwriting.\n"
     ]
    }
   ],
   "source": [
    "from redisvl.extensions.cache.llm import SemanticCache\n",
    "\n",
    "cache = SemanticCache(\n",
    "    name=\"faq-cache\",\n",
    "    vectorizer=langcache_embed,\n",
    "    redis_client=r,\n",
    "    distance_threshold=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a37aeb1",
   "metadata": {},
   "source": [
    "### Load the Cache with FAQ Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49fee799",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "for i in range(len(faq_df)):\n",
    "    cache.store(\n",
    "        prompt=faq_df.iloc[i][\"question\"],\n",
    "        response=faq_df.iloc[i][\"answer\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4baa002-c799-48e1-950e-3d3d6c2128c1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "result = cache.check(\"I need a refund for my purchase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02952a84-9fdf-47e4-85e2-c6af124c3d83",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entry_id': '60fd55b8527fcd2bf427d81dc3f4c47c4bf8904c9802ffecbcf2c02b38f537ac',\n",
       "  'prompt': 'How do I get a refund?',\n",
       "  'response': 'To request a refund, visit your orders page and select **Request Refund**. Refunds are processed within 3-5 business days.',\n",
       "  'vector_distance': 0.256070017815,\n",
       "  'inserted_at': 1763854696.46,\n",
       "  'updated_at': 1763854696.46,\n",
       "  'key': 'faq-cache:60fd55b8527fcd2bf427d81dc3f4c47c4bf8904c9802ffecbcf2c02b38f537ac'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cache-management",
   "metadata": {},
   "source": [
    "### Implement TTL (time-to-live) policy to keep cache fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91ee59fc",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "cache.set_ttl(86400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a525b4",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## End-to-End LLM Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aec528-3312-4326-b791-3f26cffe0784",
   "metadata": {
    "height": 234
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> OpenAI API key is already loaded in the environment\n"
     ]
    }
   ],
   "source": [
    "from cache.config import load_openai_key\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "load_openai_key()\n",
    "MODEL_NAME = \"qwen2:0.5b\"\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"qwen2:0.5b\", temperature=0.1, num_predict=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e32b6a58-ed65-4e9f-8884-b6121ac724de",
   "metadata": {
    "height": 202
   },
   "outputs": [],
   "source": [
    "def get_llm_response(question: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful customer support assistant. Answer this customer question concisely and professionally:\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Provide a helpful response in 1-2 sentences. If you don't have specific information, give a general helpful response.\n",
    "    \"\"\"\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    return response.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e359c0b5-bf67-4c82-b24e-109f3ff4b990",
   "metadata": {
    "height": 336
   },
   "outputs": [],
   "source": [
    "from cache.evals import PerfEval\n",
    "\n",
    "perf_eval = PerfEval()\n",
    "\n",
    "test_questions = [\n",
    "    \"How can I get my money back?\",\n",
    "    \"I want a refund please\",\n",
    "    \"What's your return policy?\",\n",
    "    \"I forgot my password\",\n",
    "    \"Can you help me reset my password?\",\n",
    "    \"What are your shipping costs?\",\n",
    "    \"Do you offer installation services?\",\n",
    "    \"Can I schedule a phone call with support?\",\n",
    "    \"How do I cancel my subscription?\",\n",
    "    \"How much does shipping cost?\",\n",
    "    \"I need to cancel my account\",\n",
    "]\n",
    "\n",
    "perf_eval.set_total_queries(len(test_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ddfcea2-8fa4-4cd8-b4eb-f6fae82a9c58",
   "metadata": {
    "height": 472
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] Question: 'How can I get my money back?'\n",
      "    ‚úÖ CACHE HIT (distance: 0.249)\n",
      "    üìã Cached question: How do I get a refund?...\n",
      "    üìã Cached response: To request a refund, visit your orders page and select **Request Refund**. Refun...\n",
      "\n",
      "[2] Question: 'I want a refund please'\n",
      "    ‚úÖ CACHE HIT (distance: 0.161)\n",
      "    üìã Cached question: How do I get a refund?...\n",
      "    üìã Cached response: To request a refund, visit your orders page and select **Request Refund**. Refun...\n",
      "\n",
      "[3] Question: 'What's your return policy?'\n",
      "    ‚ùå CACHE MISS\n",
      "    ü§ñ Calling LLM... 17:44:42 httpx INFO   HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "    üí¨ LLM response: Our return policy allows for up to 30 days for items that are not as good or‰∏çÂêàÈÄÇÔºå...\n",
      "\n",
      "[4] Question: 'I forgot my password'\n",
      "    ‚úÖ CACHE HIT (distance: 0.184)\n",
      "    üìã Cached question: Can I reset my password?...\n",
      "    üìã Cached response: Click **Forgot Password** on the login page and follow the email instructions. C...\n",
      "\n",
      "[5] Question: 'Can you help me reset my password?'\n",
      "    ‚úÖ CACHE HIT (distance: 0.060)\n",
      "    üìã Cached question: Can I reset my password?...\n",
      "    üìã Cached response: Click **Forgot Password** on the login page and follow the email instructions. C...\n",
      "\n",
      "[6] Question: 'What are your shipping costs?'\n",
      "    ‚ùå CACHE MISS\n",
      "    ü§ñ Calling LLM... 17:44:46 httpx INFO   HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "    üí¨ LLM response: Shipping costs can vary depending on the product or service you're ordering. Gen...\n",
      "\n",
      "[7] Question: 'Do you offer installation services?'\n",
      "    ‚ùå CACHE MISS\n",
      "    ü§ñ Calling LLM... 17:44:49 httpx INFO   HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "    üí¨ LLM response: Yes, I can provide assistance with your installation needs. Please let me know h...\n",
      "\n",
      "[8] Question: 'Can I schedule a phone call with support?'\n",
      "    ‚ùå CACHE MISS\n",
      "    ü§ñ Calling LLM... 17:44:50 httpx INFO   HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "    üí¨ LLM response: Yes, you can schedule a phone call with support. Just provide the details like y...\n",
      "\n",
      "[9] Question: 'How do I cancel my subscription?'\n",
      "    ‚úÖ CACHE HIT (distance: 0.000)\n",
      "    üìã Cached question: How do I cancel my subscription?...\n",
      "    üìã Cached response: Go to Account Settings > Subscriptions and click **Cancel Subscription**. You'll...\n",
      "\n",
      "[10] Question: 'How much does shipping cost?'\n",
      "    ‚úÖ CACHE HIT (distance: 0.174)\n",
      "    üìã Cached question: What are your shipping costs?...\n",
      "    üìã Cached response: Shipping costs can vary depending on the product or service you're ordering. Gen...\n",
      "\n",
      "[11] Question: 'I need to cancel my account'\n",
      "    ‚úÖ CACHE HIT (distance: 0.212)\n",
      "    üìã Cached question: How do I cancel my subscription?...\n",
      "    üìã Cached response: Go to Account Settings > Subscriptions and click **Cancel Subscription**. You'll...\n"
     ]
    }
   ],
   "source": [
    "with perf_eval:\n",
    "    for i, question in enumerate(test_questions, 1):\n",
    "        print(f\"\\n[{i}] Question: '{question}'\")\n",
    "\n",
    "        perf_eval.start()\n",
    "\n",
    "        if cached_result := cache.check(question):\n",
    "            # Cache HIT\n",
    "            perf_eval.tick(\"cache_hit\")\n",
    "            print(\n",
    "                f\"    ‚úÖ CACHE HIT (distance: {cached_result[0]['vector_distance']:.3f})\"\n",
    "            )\n",
    "            print(f\"    üìã Cached question: {cached_result[0]['prompt'][:80]}...\")\n",
    "            print(f\"    üìã Cached response: {cached_result[0]['response'][:80]}...\")\n",
    "        else:\n",
    "            # Cache MISS - call LLM\n",
    "            perf_eval.tick(\"cache_miss\")  # Time for cache check\n",
    "            print(f\"    ‚ùå CACHE MISS\")\n",
    "            print(f\"    ü§ñ Calling LLM... \", end=\"\")\n",
    "\n",
    "            # Call LLM and track the call\n",
    "            perf_eval.start()\n",
    "            llm_response = get_llm_response(question)\n",
    "            perf_eval.tick(\"llm_call\")\n",
    "            perf_eval.record_llm_call(MODEL_NAME, question, llm_response)\n",
    "            print(f\"    üí¨ LLM response: {llm_response[:80]}...\")\n",
    "            cache.store(prompt=question, response=llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24bb2a96-9142-4a55-84da-92a575d0b2fc",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11985799244471959"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(perf_eval.durations_by_label['cache_hit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe5b34bd-4b60-4a90-9201-307a73deecba",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5442482233047485"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(perf_eval.durations_by_label['llm_call'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7069e3bf-a5ef-4a25-95ec-40b47006e727",
   "metadata": {},
   "source": [
    "<b>Note:</b> In the above experiment we measure the latency of the cache response and a mocked latency of an LLM call. The mocked LLM call is a dummy function that sleeps for a random amount of time. The randomness in the results mainly comes from the randomness we introduced to mock the LLM. The results show us what we can typically see in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad2948f-1b8f-4b32-8f6f-655df47d60e2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "cache.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
